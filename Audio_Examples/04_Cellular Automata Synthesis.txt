Cellular Automata Synthesis: A Technical Overview

This Praat script generates pure synthetic audio from computational algorithms rather than processing recorded sound. It translates visual cellular automaton patterns into sonic textures by mapping grid states to sine wave frequencies, creating evolving timbral structures determined by mathematical rules.

Core Process

The script simulates discrete computational systems where cells in a grid change state based on local neighborhood rules. Each active cell generates a sine tone whose frequency corresponds to its spatial position. As the automaton evolves over time, the resulting sound morphs according to the pattern's emergent behavior—creating organic-sounding textures from deterministic algorithms.

Technical Operations

1. Three Cellular Automaton Models

Elementary CA (Wolfram Rules): One-dimensional array where each cell's next state depends on its own state plus two neighbors, encoded as an 8-bit rule number. Rule 30 (default) produces chaotic, unpredictable patterns. Rule 110 is Turing-complete. Rule 90 generates fractal Sierpinski triangles. Initialization places a single active cell at grid center.

Game of Life (Conway): Two-dimensional grid with birth/death rules based on 8-neighbor Moore neighborhoods. Underpopulation (fewer than 2 neighbors) causes death. Overpopulation (more than 3) causes death. Exactly 3 neighbors causes birth. Random initialization (30% density) creates varied evolutionary paths, from stable oscillators to chaotic glider guns.

Brian's Brain: Three-state system (off/dying/firing) where cells transition through a refractory period. Only cells with exactly 2 firing neighbors ignite. Firing cells immediately enter dying state, then return to off. Random initialization with 30% firing, 20% dying, 50% off. Produces wave-like propagation patterns with longer-lived structures than Life.

2. Spatial-to-Spectral Mapping

Each cell's position maps to a specific frequency within a defined range.

For 1D Elementary CA: frequency = base (150 Hz) + (cell_position / grid_size) × spread (200 Hz). Creates a linear frequency spectrum from 150-350 Hz distributed across 32 cells.

For 2D automata (Life, Brian's Brain): frequency = base + ((x_position + y_position) / (2 × grid_size)) × spread. Averages spatial coordinates, mapping the 2D grid to a 1D frequency space.

Grid size of 32 cells provides sufficient spectral resolution while keeping computational load manageable.

3. Temporal Segmentation

Duration is divided into discrete time segments (default 0.1 seconds each). After each segment, the automaton updates according to its rules, and a new sonic snapshot is rendered.

This creates rhythmic pulsation: sound is not continuous but composed of overlapping tonal bursts that change composition every 100ms.

4. Additive Synthesis Construction

Each active cell generates a sine wave formula wrapped in temporal conditionals.

Formula structure: IF (time >= segment_start AND time < segment_end) THEN amplitude × sin(2π × frequency × time) × envelope

Envelope uses raised-cosine window: (1 - cos(2π × local_time / duration)) / 2, creating smooth attack/decay to prevent clicks.

All cell formulas are concatenated with addition operators, building a massive compound expression that Praat evaluates sample-by-sample.

Amplitude scaling: 0.6 for Elementary CA, 0.4/grid_size for Life, 0.5/grid_size for Brian's Brain—compensating for 2D systems' higher potential cell counts.

5. Rule Evaluation and State Transitions

Elementary CA: Neighborhood pattern (left, center, right) converted to 3-bit binary index. Rule number's binary representation determines next state. Example: Rule 30 = 00011110 in binary, so pattern 001 (decimal 1) maps to bit position 1 = 1 (on).

Game of Life: Counts living neighbors in 8-cell Moore neighborhood. Applies Conway's survival/birth conditions. State updates happen simultaneously across all cells to prevent propagation artifacts.

Brian's Brain: Three-state logic with deterministic transitions. Off → Firing (if 2 firing neighbors), Firing → Dying (always), Dying → Off (always). Creates natural refractory periods preventing immediate re-triggering.

6. Boundary Conditions

Elementary CA uses zero-padding: cells outside grid boundaries are assumed dead, creating edge effects that can trap or reflect propagating patterns.

2D automata use finite grids without wrapping, causing patterns to collide with boundaries and potentially stabilize or annihilate.

7. Dynamic Formula Assembly

The script builds the synthesis formula incrementally as a string, adding each cell's contribution only when active. Final formula can contain hundreds of conditional expressions for dense 2D patterns.

Praat parses this mega-formula once during sound creation, then evaluates it sample-by-sample across the entire duration—computationally intensive but avoiding intermediate file I/O.

Compositional Implications

This generative approach produces:

Emergent rhythm from deterministic rules: Elementary CA Rule 30 creates unpredictable rhythmic density despite fixed logic. Rule 110 generates long-range correlations. The temporal pacing arises from computational behavior, not musical intuition.

Timbral evolution without transformation: Unlike processing recorded sound, the timbre evolves through changing frequency combinations rather than spectral filtering. The "orchestration" changes as cells activate/deactivate.

Non-teleological form: The piece has no compositional arc imposed by a composer—only the automaton's inherent behavior. Some rules stabilize quickly (creating static drones), others oscillate periodically (creating loops), others never repeat (creating infinite variation).

Spectral density as cellular density: Sparse patterns produce thin, whistle-like textures. Dense patterns create thick harmonic fields. The correlation between visual complexity and sonic complexity is direct.

Micro-harmonic structures: With base frequency 150 Hz and 200 Hz spread across 32 cells, adjacent cells differ by ~6 Hz—creating beating and roughness rather than clear harmonic intervals. This produces inharmonic, bell-like spectra.

Scale-free complexity: Cellular automata exhibit self-similar patterns across time scales. Short-term fluctuations mirror long-term structural changes, creating fractal-like sonic evolution.

The result is algorithmic composition where the composer selects the generative system (rule choice) but surrenders control over moment-to-moment decisions. The sound is entirely synthetic—no recording, no samples—yet can sound organic due to the automata's lifelike behavior.

Particularly striking: Brian's Brain produces wave-like sweeps as firing clusters propagate, creating natural crescendo/diminuendo gestures. Game of Life can suddenly explode with activity when a glider collides with a stable structure, producing dramatic timbral eruptions from calm textures.


Spectral Panning Mapper: A Technical Overview

This Praat script creates dynamic stereo positioning controlled by spectral characteristics of the source material. Rather than fixed or manually automated panning, the left-right distribution responds to the audio's evolving frequency content—mapping timbral qualities to spatial movement.

Core Process

The script analyzes spectral flatness (noisiness) and spectral roughness (irregularity) at multiple time points, then uses these values to modulate stereo intensity in real-time. Flat spectra create wider panning excursions, rough spectra accelerate panning motion, producing spatially animated mixes where spectral content choreographs the stereo field.

Technical Operations

1. Temporal Windowing and Channel Extraction

Duration is divided into analysis windows (default 8), creating discrete measurement points evenly distributed across the timeline.

Each window extracts a 200ms segment (±100ms around the analysis time) with Hamming tapering to reduce spectral leakage.

Mono sources are duplicated to left/right channels. Stereo sources have left channel extracted for analysis (assuming spectral content is similar between channels).

2. Spectral Flatness Calculation

Flatness measures how noise-like versus tone-like a spectrum is, computed as the ratio of geometric mean to arithmetic mean of power values.

Formula: flatness = exp(Σ ln(power_i) / N) / (Σ power_i / N)

Analysis restricted to 80-5000 Hz range, excluding infrasonic rumble and extreme treble that contribute little to perceived timbre.

Pure tones produce flatness near 0 (geometric mean much smaller than arithmetic). White noise produces flatness near 1 (both means equal).

Speech typically ranges 0.1-0.4 depending on phoneme: vowels (harmonic) score low, fricatives (noisy) score high.

3. Spectral Roughness Estimation

Roughness quantifies local spectral irregularity by measuring deviation from smoothness across adjacent frequency bins.

For each bin, compute: |amplitude_current - average(amplitude_previous, amplitude_next)|

Sum across all bins in the analysis range, normalize by number of bins.

High roughness indicates jagged, unpredictable spectra with sharp peaks and valleys. Low roughness indicates smooth spectral envelopes.

Useful for detecting rapid spectral fluctuations, amplitude modulation, or inharmonic complexity.

4. Panning Depth Modulation by Flatness

Base panning depth (default 0.3) determines minimum stereo width. Flatness influence (default 0.7) scales the additional width contributed by spectral character.

Effective depth = base + (flatness × influence)

Noisy, flat spectra (fricatives, breaths) trigger wider panning excursions, pushing sound toward hard left/right. Tonal spectra (vowels, sustained pitches) reduce excursion, keeping sound more centered.

This creates spatial differentiation based on timbre: consonants pan wide, vowels stay narrow.

5. Panning Motion Speed Modulation by Roughness

Base motion speed (default 0.5 Hz) sets the fundamental panning oscillation rate. Roughness influence (default 3.0) accelerates motion proportional to spectral irregularity.

Effective speed = base + (roughness × influence)

Smooth spectra produce slow, languid left-right sweeps. Rough, complex spectra trigger rapid, agitated panning motion.

This correlates spatial activity with spectral activity: calm sounds pan slowly, turbulent sounds pan frantically.

6. Sinusoidal Panning Trajectory with Phase Accumulation

Pan position oscillates sinusoidally, with left and right channels 90 degrees out of phase (sine/cosine relationship).

Phase accumulates over time: phase_current = phase_previous + (2π × motion_speed × time_delta)

Left gain = 50 + (depth × 50) × (1 + sin(phase))
Right gain = 50 + (depth × 50) × (1 + cos(phase))

Gain values range 10-100 dB, preventing complete silence in either channel while allowing dramatic shifts.

The quadrature relationship ensures constant total energy: when left peaks, right troughs, and vice versa.

7. Linear Interpolation Between Analysis Windows

Flatness and roughness values are interpolated linearly between consecutive analysis points, creating smooth spectral parameter transitions rather than stepped changes.

For any time t between window_i and window_i+1, compute: value(t) = value_i + progress × (value_i+1 - value_i), where progress = (t - time_i) / (time_i+1 - time_i)

This prevents abrupt panning behavior changes when crossing window boundaries.

8. High-Rate Panning Updates

Panning positions are calculated at 100 Hz (default), creating 100 discrete intensity tier points per second.

This high update rate ensures smooth panning motion without audible zipper noise or stepwise artifacts.

IntensityTiers modulate channel amplitude continuously throughout playback, implementing the calculated panning trajectory.

9. Stereo Recombination

Modified left and right channels (with time-varying intensity envelopes applied) are combined into final stereo output.

The result maintains the original spectral content but redistributes it spatially according to the extracted characteristics.

Compositional Implications

From speech or any source material, this process:

Spatializes phonetic structure: Consonants naturally pan wide due to high flatness, vowels stay centered. This creates spatial punctuation matching linguistic rhythm—sibilants sweep dramatically while sustained vowels anchor the center.

Reveals hidden spectral dynamics: Subtle timbral shifts that are hard to hear in mono become visible as spatial motion. A vowel's gradual breathiness increase manifests as widening panning excursion.

Generates autonomous spatial choreography: The panning behavior emerges from signal analysis rather than compositional decision. The composer provides mapping parameters but surrenders moment-to-moment spatial control.

Creates spectral-spatial coupling: Listeners perceive timbral change and spatial change as unified—a shift toward noisiness is simultaneously a shift toward width. This reinforces spectral perception through cross-modal correspondence.

Produces non-repetitive spatial patterns: Even cyclic source material generates unique panning trajectories because spectral content varies continuously. No two phrases occupy space identically.

Emphasizes transient events: Attacks and consonant clusters, being spectrally rough, trigger rapid panning acceleration—drawing attention to percussive moments through spatial highlighting.

The effect transforms static stereo mixes into dynamically animated spatial fields where the audio content itself determines its position. Speech becomes especially engaging, with the natural alternation between tonal and noisy phonemes creating pulsing, breathing spatial movement—the sound appears to expand and contract in the stereo field as if the utterance itself is physically gesturing.

Unlike conventional autopan effects (which impose arbitrary motion), Spectral Panning Mapper derives motion from intrinsic signal properties, creating spatial behavior that feels organically connected to the source's timbral identity.